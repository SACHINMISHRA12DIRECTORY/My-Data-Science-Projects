{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e008500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import os  # for input output\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7dfccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\PYTHON DATA SCIENCE WORK\n"
     ]
    }
   ],
   "source": [
    "#setting the working directory\n",
    "\n",
    "os.chdir(\"C:/Users/dell/PYTHON DATA SCIENCE WORK\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5849fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "train=pd.read_csv(\"train_cab.csv\",na_values = {\"pickup_datetime\":\"43\"})\n",
    "test =pd.read_csv(\"test_cab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1364d",
   "metadata": {},
   "source": [
    "# Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80251276",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head() # fare_amt is not here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27614744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4459cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes  # OBJ TO NUMERIC ALWAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec18235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e57e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42076a",
   "metadata": {},
   "source": [
    "# Hyper parameter turing to check the parameter on which are model run fast\n",
    "# Random search cv\n",
    "# Grid search cv\n",
    "# Haversine formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccba40a",
   "metadata": {},
   "source": [
    "# Data Pre Processing\n",
    "# 1)data exploration and missing value analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cbc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting fare amt from obj to numeric\n",
    "train['fare_amount'] = pd.to_numeric(train['fare_amount'],errors='coerce') # this error will convert all the non numeric value to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc2e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.dropna(subset = [\"pickup_datetime\"])  # Dropping Na values in datetime col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa549301",
   "metadata": {},
   "source": [
    "# FOR TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f51e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickup date_time is in obj we need to change its data type to datetime\n",
    "train[\"pickup_datetime\"] = pd.to_datetime(train[\"pickup_datetime\"],format='%Y-%m-%d %H:%M:%S UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seprate the pickup_datetime to seprate fields like year ,month and day\n",
    "train['year']= train['pickup_datetime'].dt.year\n",
    "train['Month']=train['pickup_datetime'].dt.month\n",
    "train['Date']=train['pickup_datetime'].dt.day\n",
    "train['Day']=train['pickup_datetime'].dt.dayofweek\n",
    "train['Hour']=train['pickup_datetime'].dt.hour\n",
    "train['Minute']=train['pickup_datetime'].dt.minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a8b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9ac8c",
   "metadata": {},
   "source": [
    "# FOR TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626914f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickup date_time is in obj we need to change its data type to datetime\n",
    "test[\"pickup_datetime\"] = pd.to_datetime(test[\"pickup_datetime\"],format='%Y-%m-%d %H:%M:%S UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa20fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seprate the pickup_datetime to seprate fields like year ,month and day\n",
    "test['year']= test['pickup_datetime'].dt.year\n",
    "test['Month']=test['pickup_datetime'].dt.month\n",
    "test['Date']=test['pickup_datetime'].dt.day\n",
    "test['Day']=test['pickup_datetime'].dt.dayofweek\n",
    "test['Hour']=test['pickup_datetime'].dt.hour\n",
    "test['Minute']=test['pickup_datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a6004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba6599",
   "metadata": {},
   "source": [
    "# Missing value analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60206104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing datetime missing value row\n",
    "train = train.drop(train[train['pickup_datetime'].isnull()].index,axis=0)\n",
    "print(train.shape)\n",
    "print(train['pickup_datetime'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['passenger_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65bee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max number of passenger_count is 5345 which is actually not possible,so reducing passenger count to 6\n",
    "train = train.drop(train[train['passenger_count']>6].index,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also removing the value with passenger count =0\n",
    "train = train.drop(train[train['passenger_count']==0].index,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['passenger_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['passenger_count'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f41e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing passenger count missiong value row\n",
    "train = train.drop(train[train['passenger_count'].isnull()].index,axis=0)\n",
    "print(train.shape)\n",
    "print(train['passenger_count'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THERE IS ONE PASSENGER COUNT OF 0.12 WHICH IS NOT POSSIBLE,HENCE REMOVE FRACTIONAL VALUE\n",
    "train = train.drop(train[train['passenger_count']==0.12].index,axis=0)\n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3bf704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0416c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding descending order of fare to get to know hwter outlier present or not\n",
    "train[\"fare_amount\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of values in which fair amt is less then 0\n",
    "Counter(train['fare_amount']<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97545118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the negative value in fare amt col\n",
    "train = train.drop(train[train['fare_amount']<0].index,axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fare_amount'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE THE ROW WHERE FAIR AMT IS 0\n",
    "train = train.drop(train[train['fare_amount']<1].index,axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38219283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a huge difference bw 1,2,3 pos in descending order of fair amt so we will remove the rows having fair amt \n",
    "train = train.drop(train[train['fare_amount']>454].index,axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fare_amount'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d01224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing fair amt missiong value row\n",
    "train = train.drop(train[train['fare_amount'].isnull()].index,axis=0)\n",
    "print(train.shape)\n",
    "print(train['fare_amount'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce8082",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"fare_amount\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd11e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"fare_amount\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649826aa",
   "metadata": {},
   "source": [
    "# Latitude can be from -90to90\n",
    "\n",
    "# longitude can be from -180to108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['pickup_latitude']<-90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['pickup_latitude']>90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677bf304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the out of range value for latitude\n",
    "train = train.drop(train[train['pickup_latitude']<-90].index,axis=0)\n",
    "train = train.drop(train[train['pickup_latitude']>90].index,axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now checking the lngitude values\n",
    "train[train['pickup_longitude']<-180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['pickup_longitude']>180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the out of range value for latitude\n",
    "train = train.drop(train[train['pickup_longitude']<-180].index,axis=0)\n",
    "train = train.drop(train[train['pickup_longitude']>180].index,axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now checking for dropof longitude and latitude\n",
    "train[train['dropoff_latitude']<-90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['dropoff_latitude']>90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4da199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['dropoff_longitude']<-180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['dropoff_longitude']>180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ede58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6589e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb63d3c",
   "metadata": {},
   "source": [
    "# CALCULATE DISTANCE BASED ON GIVEN ODINATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb65e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN THIS DATA SET WE HAVE BEEN GIVEN PICKUP LATTITUDES AND LONGITUDES AND DROP OFF LONGITUDE AND LATTITUDE\n",
    "# WE NEED TO CALCUATE THE DISTANCE USING HAVERSINE FORMULA AND WE WILL CREATE A NEW VARIABLE CALLED DISTANCE\n",
    "from math import radians ,cos , sin ,asin ,sqrt\n",
    "\n",
    "def haversine(a):\n",
    "    lon1=a[0]\n",
    "    lat1=a[1]\n",
    "    lon2=a[2]\n",
    "    lat2=a[3]\n",
    "    \n",
    "    \"calculating the great circle distance bw two points on earth\"\n",
    "    \n",
    "    #convert decimal degree to radian\n",
    "    lon1,lat1,lon2,lat2 = map(radians , [lon1,lat1,lon2,lat2])\n",
    "    #haversin formula\n",
    "    dlon=lon2-lon1\n",
    "    dlat=lat2-lat1\n",
    "    a= sin(dlat/2)**2 + cos(lat1)*cos(lat2)* sin(dlon/2)**2\n",
    "    c= 2*asin(sqrt(a))\n",
    "    #radius of earth in km is 6371\n",
    "    km = 6371 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27114a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['distance'] = train[['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_longitude']].apply(haversine,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67afd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['distance'] = test[['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_longitude']].apply(haversine,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04710c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ee78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding descending order of distance to know if outlier is present or not?\n",
    "train['distance'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50019b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27adbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['distance'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc343f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['distance'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a650b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['distance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d93653",
   "metadata": {},
   "source": [
    "THE TOP 23 DISTANCE VALUES IN THE DISTANCE VARIABLES ARE VERY HIGH , IT MEANS MORE THEN 8000 KMS DISTANCE THEY HAVE TRAVALLED\n",
    "AFTER THIS IT GOES DOWN TO 127 THERE ARE OUTLIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5fd303",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train[train['distance']>8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9f1c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a histogram\n",
    "plt.hist(train['distance'], bins=50)\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Distance')\n",
    "plt.show()\n",
    "\n",
    "# Plot a box plot\n",
    "plt.boxplot(train['distance'])\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Box Plot of Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b287ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_distance = train['distance'].mean()\n",
    "median_distance = train['distance'].median()\n",
    "std_distance = train['distance'].std()\n",
    "\n",
    "print(f\"Mean Distance: {mean_distance}\")\n",
    "print(f\"Median Distance: {median_distance}\")\n",
    "print(f\"Standard Deviation: {std_distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = mean_distance + 3 * std_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab045e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will remove the row distance value which is more then 129\n",
    "train = train.drop(train[train['distance']>17732.50].index,axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ad6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(train['distance']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6760c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(test['distance']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf14d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(train['fare_amount']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c963767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will remove the row distance value which is 0\n",
    "train = train.drop(train[train['distance']==0].index,axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(test[test['distance']==0].index,axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6499ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214ac1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fbfc63b",
   "metadata": {},
   "source": [
    " WE HAVE SPLITTED THE PICKUP_DATE TIME INTO YEAR,MONTH,DAY,HOUR,MINUTE SO WE ARE DROPPING PICKUP_DATE , dropping long and lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2995831",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','Minute']\n",
    "train = train.drop(drop_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df261c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','Minute']\n",
    "test = test.drop(drop_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966bb85",
   "metadata": {},
   "source": [
    "# Converting variables to Float Data Type to Int Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['passenger_count'] = train['passenger_count'].astype('int64')\n",
    "train['year'] = train['year'].astype('int64')\n",
    "train['Month'] = train['Month'].astype('int64')\n",
    "train['Date'] = train['Date'].astype('int64')\n",
    "train['Day'] = train['Day'].astype('int64')\n",
    "train['Hour'] = train['Hour'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8857132",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3135d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78464f59",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "number of passanger effect the fair\n",
    "pickup date and time effect the fair\n",
    "day of the week does affect the fair\n",
    "distance effect the fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ffd077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#count plot\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(x=\"passenger_count\",data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b56f361",
   "metadata": {},
   "source": [
    "single and double passanger are frequent riders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ebcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship bw number f passager and fair\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['passenger_count'],y=train['fare_amount'],s=10)\n",
    "plt.xlabel(\"Number of passangers\")\n",
    "plt.ylabel(\"Fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d953b8",
   "metadata": {},
   "source": [
    "single and double passenger had the maximum fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship bw date and fair\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['Date'],y=train['fare_amount'],s=10)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052015c",
   "metadata": {},
   "source": [
    "fair is almost equal in all days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41709959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationshio bw the hour of day and fair\n",
    "plt.figure(figsize=(15,7))\n",
    "train.groupby(train['Hour'])['Hour'].count().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f1068",
   "metadata": {},
   "source": [
    "lowest number of cabs were around 5am and highest number of cabs were around bw 6pm to 7 pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2481a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship bw time and fare\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['Hour'],y=train['fare_amount'],s=10)\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Fare\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f2793",
   "metadata": {},
   "source": [
    "Fare is highest at 7am and around 11 pm which tells the fair is highest in early  morning and late nights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf2497",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb00db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship bw day of the week  and number of cab rides\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(x='Day',data= train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a5bcc0",
   "metadata": {},
   "source": [
    "Not much relation bw day of the week and the count of number of cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485798d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship bw Day and fare\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['Day'],y=train['fare_amount'],s=10)\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Fare\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9dab2c",
   "metadata": {},
   "source": [
    "the highest fare seems to be on sunday,monday and thursday and  low on wednesday and thursday , may be due to low demand on cabs on saturday the cab fare is too low and high demand of cabs on sunday and monday show the high fare price......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship bw distance and fare\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['distance'],y=train['fare_amount'],c='g')\n",
    "plt.xlabel(\"distance\")\n",
    "plt.ylabel(\"Fare\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36da9f6",
   "metadata": {},
   "source": [
    "distance is direcly propotional to fare charge as the distance is increasing fare charge also increasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec21f5",
   "metadata": {},
   "source": [
    "# Feacture Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe3244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the traning data which is uniformally distributed or not\n",
    "for i in ['fare_amount','distance']:\n",
    "    print(i)\n",
    "    sns.displot(train[i],bins='auto',color='green')\n",
    "    plt.title(\"distribution of variable \"+i)\n",
    "    plt.ylabel('density')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# right skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e779dd",
   "metadata": {},
   "source": [
    "# log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the fair amt is hihlt skewed applying log transformation\n",
    "train['fare_amount'] = np.log1p(train['fare_amount'])\n",
    "\n",
    "# since variable distance is highly skewed\n",
    "train['distance'] = np.log1p(train['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028d37b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in ['fare_amount','distance']:\n",
    "    print(i)\n",
    "    sns.displot(train[i],bins='auto',color='green')\n",
    "    plt.title(\"distribution of variable \"+i)\n",
    "    plt.ylabel('density')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df97f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the test data which is uniformally distributed or not\n",
    "for i in ['distance']:\n",
    "    print(i)\n",
    "    sns.displot(test[i],bins='auto',color='green')\n",
    "    plt.title(\"distribution of variable \"+i)\n",
    "    plt.ylabel('density')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since variable distance is highly skewed\n",
    "test['distance'] = np.log1p(test['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d6c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the test data which is uniformally distributed or not\n",
    "for i in ['distance']:\n",
    "    print(i)\n",
    "    sns.displot(test[i],bins='auto',color='green')\n",
    "    plt.title(\"distribution of variable \"+i)\n",
    "    plt.ylabel('density')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0c15e5",
   "metadata": {},
   "source": [
    "# Applying ML  Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacab416",
   "metadata": {},
   "source": [
    "1 data modelling\n",
    "2 decision tree\n",
    "3 random forest\n",
    "4 gradient boosting\n",
    "5 Hyper parameter turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test spilt for further modelling                                          train                 \n",
    "X_train, X_test, y_train, y_test = train_test_split(train.iloc[:,train.columns !='fare_amount'],train.iloc[:,0],test_size=.20,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc219db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train   #OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4dbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa106b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bae2e4",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model on top of traning dataset\n",
    "fit_LR = LinearRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeeca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on traning dataset\n",
    "pred_train_LR = fit_LR.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on test data\n",
    "pred_test_LR = fit_LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195daadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating rmse test data\n",
    "RMSE_test_LR = np.sqrt(mean_squared_error(y_test,pred_test_LR))\n",
    "\n",
    "# calculating rmse for train data\n",
    "RMSE_train_LR = np.sqrt(mean_squared_error(y_train,pred_train_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c276d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root mean square error for Traning data =\"+str(RMSE_train_LR))\n",
    "print(\"Root mean square error for Test data =\"+str(RMSE_test_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafa911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r62 for train data\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train , pred_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9291e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,pred_test_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30662b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b40f57",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_DT = DecisionTreeRegressor(max_depth=2).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51bb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on train data\n",
    "pred_train_DT = fit_DT.predict(X_train)\n",
    "\n",
    "#prediction on test data\n",
    "pred_test_DT = fit_DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating rmse test data\n",
    "RMSE_test_DT = np.sqrt(mean_squared_error(y_test,pred_test_DT))\n",
    "\n",
    "# calculating rmse for train data\n",
    "RMSE_train_DT = np.sqrt(mean_squared_error(y_train,pred_train_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root mean square error for Traning data =\"+str(RMSE_train_DT))\n",
    "print(\"Root mean square error for Test data =\"+str(RMSE_test_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1192b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r62 for train data\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train , pred_train_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test , pred_test_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5f2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e8ce399",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c40126",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_RF = RandomForestRegressor(n_estimators=200).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f21f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on train data\n",
    "pred_train_RF = fit_RF.predict(X_train)\n",
    "\n",
    "#prediction on test data\n",
    "pred_test_RF = fit_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating rmse test data\n",
    "RMSE_test_RF = np.sqrt(mean_squared_error(y_test,pred_test_RF))\n",
    "\n",
    "# calculating rmse for train data\n",
    "RMSE_train_RF = np.sqrt(mean_squared_error(y_train,pred_train_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root mean square error for Traning data =\"+str(RMSE_train_RF))\n",
    "print(\"Root mean square error for Test data =\"+str(RMSE_test_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9635b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r62 for train data\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train , pred_train_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test , pred_test_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcfa450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61e6732f",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_GB = GradientBoostingRegressor().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on train data\n",
    "pred_train_GB = fit_GB.predict(X_train)\n",
    "\n",
    "#prediction on test data\n",
    "pred_test_GB = fit_GB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating rmse test data\n",
    "RMSE_test_GB = np.sqrt(mean_squared_error(y_test,pred_test_GB))\n",
    "\n",
    "# calculating rmse for train data\n",
    "RMSE_train_GB = np.sqrt(mean_squared_error(y_train,pred_train_GB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root mean square error for Traning data =\"+str(RMSE_train_GB))\n",
    "print(\"Root mean square error for Test data =\"+str(RMSE_test_GB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a21262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r62 for train data\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train , pred_train_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test , pred_test_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62329983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e8ab106",
   "metadata": {},
   "source": [
    "## Parameter turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "from pprint import pprint\n",
    "#look at the parameter used by this\n",
    "print('parameter currently in used')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c6788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random hyperparameter grid\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random search cv on random forest model\n",
    "\n",
    "RRF = RandomForestRegressor(random_state =0)\n",
    "n_estimator = list(range(1,20,2))\n",
    "depth = list(range(1,100,2))\n",
    "\n",
    "# Create the random grid\n",
    "rand_grid = {'n_estimators':n_estimator,\n",
    "              'max_depth' : depth}\n",
    "\n",
    "randomcv_rf = RandomizedSearchCV(RRF,param_distributions = rand_grid ,n_iter = 5,cv=5,random_state=0)\n",
    "randomcv_rf = randomcv_rf.fit(X_train,y_train)\n",
    "predictions_RRF = randomcv_rf.predict(X_test)\n",
    "\n",
    "view_best_params_RRF = randomcv_rf.best_params_\n",
    "\n",
    "best_model = randomcv_rf.best_estimator_\n",
    "\n",
    "predictions_RRF = best_model.predict(X_test)\n",
    "\n",
    "RRF_r2 = r2_score(y_test,predictions_RRF)\n",
    "\n",
    "# calculating rmse\n",
    "RRF_rmse = np.sqrt(mean_squared_error(y_test,predictions_RRF))\n",
    "\n",
    "print(\"Random Search cv on Random forest Regressor Model performance: \")\n",
    "print(\"Best Parameter:\",view_best_params_RRF)\n",
    "print(\"R-Squared = {:0.2}\".format(RRF_r2))\n",
    "print(\"RMSE \",RRF_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641bc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e32b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying random search cv Gradient Boosting\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "from pprint import pprint\n",
    "#look at the parameter used by this\n",
    "print('parameter currently in used')\n",
    "pprint(gb.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random search cv on Gradient Boosting model\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "n_estimator = list(range(1,20,2))\n",
    "depth = list(range(1,100,2))\n",
    "\n",
    "# Create the random grid\n",
    "rand_grid = {'n_estimators':n_estimator,\n",
    "              'max_depth' : depth}\n",
    "\n",
    "randomcv_gb = RandomizedSearchCV(gb,param_distributions = rand_grid ,n_iter = 5,cv=5,random_state=0)\n",
    "randomcv_gb = randomcv_gb.fit(X_train,y_train)\n",
    "predictions_gb = randomcv_gb.predict(X_test)\n",
    "\n",
    "view_best_params_gb = randomcv_gb.best_params_\n",
    "\n",
    "best_model = randomcv_gb.best_estimator_\n",
    "\n",
    "predictions_gb = best_model.predict(X_test)\n",
    "\n",
    "gb_r2 = r2_score(y_test,predictions_RRF)\n",
    "\n",
    "# calculating rmse\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test,predictions_RRF))\n",
    "\n",
    "print(\"Random Search cv Gradient Boosting Model performance: \")\n",
    "print(\"Best Parameter:\",view_best_params_gb)\n",
    "print(\"R-Squared = {:0.2}\".format(gb_r2))\n",
    "print(\"RMSE \",gb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae6766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19e675ac",
   "metadata": {},
   "source": [
    "## Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aafd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search CV on random forest model\n",
    "\n",
    "GRF = RandomForestRegressor(random_state =0)\n",
    "n_estimator = list(range(11,20,1))\n",
    "depth = list(range(5,15,12))\n",
    "\n",
    "# Create the random grid\n",
    "grid_search = {'n_estimators':n_estimator,\n",
    "              'max_depth' : depth}\n",
    "\n",
    "# Grid Search cross validation with 5 folds cv\n",
    "gridcv_rf = GridSearchCV(RRF,param_grid = grid_search ,cv=5)\n",
    "gridcv_RF = gridcv_rf.fit(X_train,y_train)\n",
    "predictions_GRF = gridcv_RF.predict(X_test)\n",
    "\n",
    "#view_best_params_RRF = gridcv_RF.best_params_\n",
    "\n",
    "best_model = gridcv_RF.best_estimator_\n",
    "\n",
    "predictions_GRF = best_model.predict(X_test)\n",
    "\n",
    "GRF_r2 = r2_score(y_test,predictions_RRF)\n",
    "\n",
    "# calculating rmse\n",
    "GRF_rmse = np.sqrt(mean_squared_error(y_test,predictions_GRF))\n",
    "\n",
    "print(\"Random Search cv on Random forest Regressor Model performance: \")\n",
    "#print(\"Best Parameter:\",view_best_params_GRF)\n",
    "print(\"R-Squared = {:0.2}\".format(GRF_r2))\n",
    "print(\"RMSE \",GRF_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356db230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a407a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search CV on Gradient Boosting\n",
    "\n",
    "GGB = GradientBoostingRegressor(random_state=42)\n",
    "n_estimator = list(range(11,20,1))\n",
    "depth = list(range(5,15,12))\n",
    "\n",
    "# Create the random grid\n",
    "grid_search = {'n_estimators':n_estimator,\n",
    "              'max_depth' : depth}\n",
    "\n",
    "# Grid Search cross validation with 5 folds cv\n",
    "gridcv_GB = GridSearchCV(GGB,param_grid = grid_search ,cv=5)\n",
    "gridcv_GB = gridcv_rf.fit(X_train,y_train)\n",
    "predictions_GGB = gridcv_GB.predict(X_test)\n",
    "\n",
    "view_best_params_GGB = gridcv_GB.best_params_\n",
    "\n",
    "best_model = gridcv_GB.best_estimator_\n",
    "\n",
    "predictions_GGB = best_model.predict(X_test)\n",
    "\n",
    "GGB_r2 = r2_score(y_test,predictions_RRF)\n",
    "\n",
    "# calculating rmse\n",
    "GGB_rmse = np.sqrt(mean_squared_error(y_test,predictions_GGB))\n",
    "\n",
    "print(\"Grid Search CV on Gradient Boosting Model performance: \")\n",
    "print(\"Best Parameter:\",view_best_params_GGB)\n",
    "print(\"R-Squared = {:0.2}\".format(GGB_r2))\n",
    "print(\"RMSE \",GGB_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f361c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3d2089e",
   "metadata": {},
   "source": [
    "## Predictions of fare from provided test  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132dd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search CV for random forest model\n",
    "\n",
    "regr = RandomForestRegressor(random_state =0)\n",
    "n_estimator = list(range(11,20,1))\n",
    "depth = list(range(5,15,2))\n",
    "\n",
    "# Create the random grid\n",
    "grid_search = {'n_estimators':n_estimator,\n",
    "              'max_depth' : depth}\n",
    "\n",
    "# Grid Search cross validation with 5 folds cv\n",
    "gridcv_rf = GridSearchCV(regr,param_grid = grid_search ,cv=5)\n",
    "gridcv_rf = gridcv_rf.fit(X_train,y_train)\n",
    "predictions_GRF = gridcv_rf.predict(X_test)\n",
    "\n",
    "view_best_params_RRF = gridcv_RF.best_params_\n",
    "\n",
    "# Apply model on Test data\n",
    "predictions_GRF_test = gridcv_rf.predict(test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_GRF_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predicted_fare'] = predictions_GRF_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c113b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ec99e",
   "metadata": {},
   "source": [
    "##  OUTPUT  STORING IN FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523adec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
